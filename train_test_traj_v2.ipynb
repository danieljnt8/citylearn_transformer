{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b40e6cf8-275c-4070-9d22-11873341a546",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: Gym version v0.24.0 has a number of critical issues with `gym.make` such that the `reset` and `step` functions are called before returning the environment. It is recommend to downgrading to v0.23.1 or upgrading to v0.25.1\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "import wandb\n",
    "\n",
    "import pickle\n",
    "from tqdm.auto import trange, tqdm\n",
    "from torch.utils.data import Dataset\n",
    "from dataclasses import dataclass\n",
    "from datasets import load_from_disk\n",
    "from omegaconf import OmegaConf\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\"\"\"\n",
    "from citylearn.agents.rbc import HourRBC\n",
    "from citylearn.agents.q_learning import TabularQLearning\n",
    "from citylearn.citylearn import CityLearnEnv\n",
    "from citylearn.data import DataSet\n",
    "from citylearn.reward_function import RewardFunction\n",
    "from citylearn.wrappers import NormalizedObservationWrapper\n",
    "from citylearn.wrappers import StableBaselines3Wrapper\n",
    "from citylearn.wrappers import TabularQLearningWrapper\n",
    "\"\"\"\n",
    "from stable_baselines3.a2c import A2C\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from trajectory.models.gpt import GPT, GPTTrainer\n",
    "\n",
    "from trajectory.utils.common import pad_along_axis\n",
    "from trajectory.utils.discretization import KBinsDiscretizer\n",
    "from trajectory.utils.env import create_env\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ccc7d5d9-f323-41c8-86fc-8b92360677c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "80baffec-e634-4bc3-901f-304bb8701c7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "offline_data_path = \"data_interactions/best_dataset.pkl\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bbd8393c-4744-4f29-9d65-e6f7bee81a17",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_from_disk(offline_data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b87e0b22-c04e-44b1-a86e-297add011795",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['observations', 'next_observations', 'actions', 'rewards', 'dones', 'info'],\n",
       "    num_rows: 8759\n",
       "})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3dd62a1d-1d5b-487f-8bd8-5f416e8340d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8759, 44)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(dataset[\"observations\"]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9fabcab7-d2f3-4cb7-928b-989f7ab6436b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def join_trajectory(states, actions, rewards, discount=0.99):\n",
    "    traj_length = states.shape[0]\n",
    "    # I can vectorize this for all dataset as once,\n",
    "    # but better to be safe and do it once and slow and right (and cache it)\n",
    "    \n",
    "    if actions.ndim == 3 :\n",
    "        actions = actions.reshape(actions.shape[0],actions.shape[1])\n",
    "    \n",
    "    if rewards.ndim == 1 :\n",
    "        rewards = rewards.reshape(rewards.shape[0],1)\n",
    "        \n",
    "    print(\"Discount \"+str(discount))\n",
    "    discounts = (discount ** np.arange(traj_length))\n",
    "\n",
    "    values = np.zeros_like(rewards)\n",
    "    for t in range(traj_length):\n",
    "        # discounted return-to-go from state s_t:\n",
    "        # r_{t+1} + y * r_{t+2} + y^2 * r_{t+3} + ...\n",
    "        # .T as rewards of shape [len, 1], see https://github.com/Howuhh/faster-trajectory-transformer/issues/9\n",
    "        values[t] = (rewards[t + 1:].T * discounts[:-t - 1]).sum()\n",
    "    print(states.shape)\n",
    "    print(actions.shape)\n",
    "    print(rewards.shape)\n",
    "    print(values.shape)\n",
    "\n",
    "    joined_transition = np.concatenate([states, actions, rewards, values], axis=-1)\n",
    "\n",
    "    return joined_transition\n",
    "\n",
    "def segment(states, actions, rewards, terminals):\n",
    "    assert len(states) == len(terminals)\n",
    "    \n",
    "    trajectories = {}\n",
    "\n",
    "    episode_num = 0\n",
    "    for t in trange(len(terminals), desc=\"Segmenting\"):\n",
    "        if episode_num not in trajectories:\n",
    "            trajectories[episode_num] = {\n",
    "                \"states\": [],\n",
    "                \"actions\": [],\n",
    "                \"rewards\": []\n",
    "            }\n",
    "        \n",
    "        trajectories[episode_num][\"states\"].append(states[t])\n",
    "        trajectories[episode_num][\"actions\"].append(actions[t])\n",
    "        trajectories[episode_num][\"rewards\"].append(rewards[t])\n",
    "\n",
    "        if terminals[t]:\n",
    "            # next episode\n",
    "            episode_num = episode_num + 1\n",
    "\n",
    "    trajectories_lens = [len(v[\"states\"]) for k, v in trajectories.items()]\n",
    "\n",
    "    for t in trajectories:\n",
    "        trajectories[t][\"states\"] = np.stack(trajectories[t][\"states\"], axis=0)\n",
    "        trajectories[t][\"actions\"] = np.stack(trajectories[t][\"actions\"], axis=0)\n",
    "        trajectories[t][\"rewards\"] = np.stack(trajectories[t][\"rewards\"], axis=0)\n",
    "\n",
    "    return trajectories, trajectories_lens\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "962c1c07-0b48-4875-acda-5abee0f4f606",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9016b3d4fe4a4e95a13ddcef3d42afd0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Segmenting:   0%|          | 0/8759 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "trajectories,traj_lengths = segment(dataset[\"observations\"],dataset[\"actions\"],dataset[\"rewards\"],dataset[\"dones\"])\n",
    "joined_transitions=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0c321280-8426-4e80-8c49-08a5a4de13a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "26c3d818f61e427f9d7aff32b2d4028c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Joining transitions:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Discount 0.99\n",
      "(8759, 44)\n",
      "(8759, 5)\n",
      "(8759, 1)\n",
      "(8759, 1)\n"
     ]
    }
   ],
   "source": [
    "for t in tqdm(trajectories, desc=\"Joining transitions\"):\n",
    "    joined_transitions.append(\n",
    "                    join_trajectory(trajectories[t][\"states\"], trajectories[t][\"actions\"], trajectories[t][\"rewards\"],discount = 0.99)\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7dce8250-7768-4d60-a167-a31e39e92b2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_bins = 100\n",
    "strategy = \"uniform\"\n",
    "discretizer = KBinsDiscretizer(\n",
    "            np.concatenate(joined_transitions, axis=0),\n",
    "            num_bins=num_bins,\n",
    "            strategy=strategy\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "76657746-09af-49e9-ac4c-531da6d90edc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<trajectory.utils.discretization.KBinsDiscretizer at 0x7fd0156dc100>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "discretizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a41c7263-9a5e-46de-97d2-8ae268a05077",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DiscretizedDataset(Dataset):\n",
    "    def __init__(self, dataset,env_name=\"city_learn\", num_bins=100, seq_len=10, discount=0.99, strategy=\"uniform\", cache_path=\"data\"):\n",
    "        self.seq_len = seq_len\n",
    "        self.discount = discount\n",
    "        self.num_bins = num_bins\n",
    "        self.dataset = dataset\n",
    "        self.env_name = env_name\n",
    "        \n",
    "        trajectories, traj_lengths = segment(self.dataset[\"observations\"],self.dataset[\"actions\"],self.dataset[\"rewards\"],self.dataset[\"dones\"])\n",
    "        self.trajectories = trajectories\n",
    "        self.traj_lengths = traj_lengths\n",
    "        self.cache_path = cache_path\n",
    "        self.cache_name = f\"{env_name}_{num_bins}_{seq_len}_{strategy}_{discount}\"\n",
    "        \n",
    "        self.joined_transitions = []\n",
    "        for t in tqdm(trajectories, desc=\"Joining transitions\"):\n",
    "            self.joined_transitions.append(\n",
    "                    join_trajectory(trajectories[t][\"states\"], trajectories[t][\"actions\"], trajectories[t][\"rewards\"],discount = self.discount)\n",
    "                )\n",
    "        \"\"\"\n",
    "        if cache_path is None or not os.path.exists(os.path.join(cache_path, self.cache_name)):\n",
    "            self.joined_transitions = []\n",
    "            for t in tqdm(trajectories, desc=\"Joining transitions\"):\n",
    "                self.joined_transitions.append(\n",
    "                    join_trajectory(trajectories[t][\"states\"], trajectories[t][\"actions\"], trajectories[t][\"rewards\"],discount = self.discount)\n",
    "                )\n",
    "\n",
    "            os.makedirs(os.path.join(cache_path), exist_ok=True)\n",
    "            # save cached version\n",
    "            with open(os.path.join(cache_path, self.cache_name), \"wb\") as f:\n",
    "                pickle.dump(self.joined_transitions, f)\n",
    "        else:\n",
    "            with open(os.path.join(cache_path, self.cache_name), \"rb\") as f:\n",
    "                self.joined_transitions = pickle.load(f)\n",
    "        \"\"\"\n",
    "\n",
    "        self.discretizer = KBinsDiscretizer(\n",
    "            np.concatenate(self.joined_transitions, axis=0),\n",
    "            num_bins=num_bins,\n",
    "            strategy=strategy\n",
    "        )\n",
    "\n",
    "        # get valid indices for seq_len sampling\n",
    "        indices = []\n",
    "        for path_ind, length in enumerate(traj_lengths):\n",
    "            end = length - 1\n",
    "            for i in range(end):\n",
    "                indices.append((path_ind, i, i + self.seq_len))\n",
    "        self.indices = np.array(indices)\n",
    "\n",
    "    def get_env_name(self):\n",
    "        return self.env.name\n",
    "\n",
    "    def get_discretizer(self):\n",
    "        return self.discretizer\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.indices)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        #print(idx)\n",
    "        traj_idx, start_idx, end_idx = self.indices[idx]\n",
    "        \n",
    "        joined = self.joined_transitions[traj_idx][start_idx:end_idx]\n",
    "        \n",
    "\n",
    "        loss_pad_mask = np.ones((self.seq_len, joined.shape[-1]))\n",
    "        if joined.shape[0] < self.seq_len:\n",
    "            # pad to seq_len if at the end of trajectory, mask for padding\n",
    "            loss_pad_mask[joined.shape[0]:] = 0\n",
    "            joined = pad_along_axis(joined, pad_to=self.seq_len, axis=0)\n",
    "\n",
    "        joined_discrete = self.discretizer.encode(joined).reshape(-1).astype(np.longlong)\n",
    "        loss_pad_mask = loss_pad_mask.reshape(-1)\n",
    "\n",
    "        return joined_discrete[:-1], joined_discrete[1:], loss_pad_mask[:-1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "81e435b0-cdf2-49cb-9b7c-026cb722e839",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ml-stud15/anaconda3/envs/stable3/lib/python3.9/site-packages/notebook/utils.py:280: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n",
      "  return LooseVersion(v) >= LooseVersion(check)\n"
     ]
    }
   ],
   "source": [
    "config = OmegaConf.load(\"configs/medium/city_learn.yaml\")\n",
    "wandb.init(\n",
    "        **config.wandb,\n",
    "        config=dict(OmegaConf.to_container(config, resolve=True))\n",
    "    )\n",
    "device = \"cuda:0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "25748ab5-7790-4465-8a6f-5e542d8f7eae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0f1be5e6954540a081d697ad16e909b5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Segmenting:   0%|          | 0/8759 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "daf90562382e463a8cc3ba1fd103357a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Joining transitions:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Discount 0.99\n",
      "(8759, 44)\n",
      "(8759, 5)\n",
      "(8759, 1)\n",
      "(8759, 1)\n"
     ]
    }
   ],
   "source": [
    "datasets = DiscretizedDataset(dataset,discount = 0.99)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4c555029-ab15-4ab9-bece-d90901c78ab9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(51,)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datasets.joined_transitions[0][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1d19225b-8c50-40c3-8be3-c7c0ffe884ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 1\n",
    "dataloader = DataLoader(datasets, batch_size=batch_size, shuffle=True, num_workers=8, pin_memory=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "909e1ec9-6b5d-461a-bfc2-03dff1271912",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda:0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "b97f03b8-70bd-45e5-a5b8-62abc6ca6816",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3af494aafc7f4039925dc527c1c712f2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch:   0%|          | 0/8758 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for i, batch in enumerate(tqdm(dataloader, desc=\"Epoch\", leave=False)):\n",
    "    batch = [b.to(device) for b in batch]\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "51d7a38d-1225-4d5a-bb97-68eadb0e37c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens, targets, loss_pad_mask = batch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8078e505-fc06-4d1a-a102-72a023e33eea",
   "metadata": {},
   "source": [
    "### Training Part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "058987b4-f81a-459b-a98e-545fabe31436",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7fcf8c8fa430>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ml-stud15/anaconda3/envs/stable3/lib/python3.9/site-packages/torch/utils/data/dataloader.py\", line 1479, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/home/ml-stud15/anaconda3/envs/stable3/lib/python3.9/site-packages/torch/utils/data/dataloader.py\", line 1443, in _shutdown_workers\n",
      "    w.join(timeout=_utils.MP_STATUS_CHECK_INTERVAL)\n",
      "  File \"/home/ml-stud15/anaconda3/envs/stable3/lib/python3.9/multiprocessing/process.py\", line 149, in join\n",
      "    res = self._popen.wait(timeout)\n",
      "  File \"/home/ml-stud15/anaconda3/envs/stable3/lib/python3.9/multiprocessing/popen_fork.py\", line 40, in wait\n",
      "    if not wait([self.sentinel], timeout):\n",
      "  File \"/home/ml-stud15/anaconda3/envs/stable3/lib/python3.9/multiprocessing/connection.py\", line 936, in wait\n",
      "    ready = selector.select(timeout)\n",
      "  File \"/home/ml-stud15/anaconda3/envs/stable3/lib/python3.9/selectors.py\", line 416, in select\n",
      "    fd_event_list = self._selector.poll(timeout)\n",
      "KeyboardInterrupt: \n"
     ]
    }
   ],
   "source": [
    "path = \"configs/medium/city_learn.yaml\"\n",
    "config = OmegaConf.load(\"configs/medium/city_learn_traj.yaml\")\n",
    "trainer_conf = config.trainer\n",
    "data_conf = config.dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "cb49b6ee-9778-414a-a103-3ed3e1c73686",
   "metadata": {},
   "outputs": [],
   "source": [
    "tok_embd = nn.Embedding(100 * 51, 128).to('cuda:0')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "06ff2dea-9c6d-45b8-a1f3-a0b944b56654",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 330, 128])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.pos_emb.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "c7cee6bb-c9a2-4acd-a9d4-742c387e685a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[93, 58, 98, 28, 18, 47, 22, 65, 71, 48, 74,  0,  1, 53,  0,  0,  4, 79,\n",
       "          0,  8,  0,  0,  0,  0,  7,  0, 10, 46, 12,  0,  0, 43,  0,  0,  6, 36,\n",
       "          5,  0, 42, 44,  8,  0, 54, 45, 57, 55, 49, 50, 49, 83, 60, 93, 58, 93,\n",
       "         27, 28, 47, 22, 63, 60, 48, 68,  0, 11, 44,  0,  0, 45, 71,  0,  8,  0,\n",
       "          0,  0,  0,  6,  0, 10, 45,  8,  0,  0, 44,  0,  0,  6, 36,  5,  0, 43,\n",
       "         44, 10,  0, 54, 46, 57, 55, 49, 50, 49, 84, 60, 93, 58, 85, 22, 37, 43,\n",
       "         20, 65, 53, 61, 71,  0, 28, 33,  0,  0, 71, 73,  0,  8,  0,  0,  0,  0,\n",
       "          7,  0,  9, 46,  6,  0,  0, 41,  0,  0,  5, 36,  5,  0, 43, 44, 10,  0,\n",
       "         54, 46, 56, 56, 49, 50, 34, 84, 59, 93, 58, 75, 22, 41, 41, 20, 65, 61,\n",
       "         70, 68,  0, 43, 17,  0,  0, 82, 56,  0, 10,  0,  0, 87,  0,  8,  0,  8,\n",
       "         46,  5,  0,  0, 40,  0,  0,  5, 36,  6,  0, 44, 44, 32,  0, 35, 47, 55,\n",
       "         56, 49, 50, 39, 84, 59, 93, 58, 62, 20, 47, 37, 16, 65, 51, 82, 77,  0,\n",
       "         54,  3,  0,  0, 87, 14,  0, 15,  0,  0, 87,  0,  9,  0,  5, 46,  5,  0,\n",
       "          1, 40,  0,  0,  4, 36,  5,  0, 45, 44, 25,  0, 22, 47, 53, 56, 48, 50,\n",
       "          0, 83, 59, 93, 58, 50, 18, 50, 35, 16, 74, 47, 78, 77,  0, 58,  0,  0,\n",
       "          0, 88,  0,  0, 23,  0,  0, 87,  0, 11,  0,  0, 46,  5,  0,  1, 41,  1,\n",
       "          0,  2, 36,  6,  0, 45, 43, 38,  0,  0, 49, 57, 56, 47, 26, 50, 84, 59,\n",
       "         93, 58, 37, 18, 47, 33, 18, 71, 48, 85, 77,  1, 53,  0,  1,  4, 79,  0,\n",
       "          4, 25,  0,  0, 87,  0,  8, 22,  0, 32,  6,  2,  3, 40,  3,  2,  0, 36,\n",
       "         32,  2, 17, 44, 27, 32,  0, 41, 61, 53, 49, 35, 67, 84, 59, 93, 58, 25,\n",
       "         28, 47, 35, 24, 60, 48, 82, 63, 11, 44,  0, 11, 45, 71,  0, 44, 29,  0,\n",
       "          0, 87,  0,  6, 47,  3, 17, 13,  9,  0, 42,  4,  8,  0, 36, 26,  8,  0,\n",
       "         45, 18, 55, 17, 41, 71, 55, 54, 49, 75, 86, 59, 93, 58, 14, 37, 43, 33,\n",
       "         28, 53, 61, 82, 75, 28, 33,  0, 20, 71, 73,  0, 37, 30,  0,  0,  0,  0,\n",
       "          4, 64, 19, 17, 19, 28,  0, 41,  1, 27,  4, 24, 21, 27,  0, 45, 15, 69,\n",
       "         43, 41, 76, 67, 63, 55, 54, 90, 59, 93, 58,  6, 41, 41, 33, 37, 61, 70,\n",
       "         82, 78, 43, 17,  0, 42, 82, 56,  0, 70, 34,  0, 87,  0,  0,  4, 74, 41,\n",
       "         16, 10, 45, 13, 36,  0, 45, 17, 24, 23, 45,  5, 42, 50, 75, 47, 41, 75,\n",
       "         71, 68, 56, 54, 92]], device='cuda:0')"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "e8b7ebaa-fd0c-4de2-93a7-005bbafc72de",
   "metadata": {},
   "outputs": [],
   "source": [
    "token_embeddings = tok_embd(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "975d455c-aec7-47a1-b9cc-3162be60b684",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPT(\n",
       "  (tok_emb): Embedding(3300, 128)\n",
       "  (drop_emb): Dropout(p=0.1, inplace=False)\n",
       "  (blocks): ModuleList(\n",
       "    (0-3): 4 x TransformerBlock(\n",
       "      (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "      (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "      (drop): Dropout(p=0.1, inplace=False)\n",
       "      (attention): MultiheadAttention(\n",
       "        (out_proj): NonDynamicallyQuantizableLinear(in_features=128, out_features=128, bias=True)\n",
       "      )\n",
       "      (mlp): Sequential(\n",
       "        (0): Linear(in_features=128, out_features=512, bias=True)\n",
       "        (1): GELU(approximate='none')\n",
       "        (2): Linear(in_features=512, out_features=128, bias=True)\n",
       "        (3): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "  (head): EinLinear(n_models=33, in_features=128, out_features=100, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = GPT(**config.model)\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4d6918e5-c23d-4e2f-b1d2-8cfe4484a32e",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens, targets, loss_pad_mask = batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "dd16eb03-acce-400a-addf-d23a015870aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerBlock(nn.Module):\n",
    "    \"\"\" Pre-norm transformer block \"\"\"\n",
    "    def __init__(self, transition_dim, seq_len, embedding_dim, num_heads, attention_dropout, residual_dropout):\n",
    "        super().__init__()\n",
    "        self.seq_len = seq_len\n",
    "        self.norm1 = nn.LayerNorm(embedding_dim).to('cuda:0')\n",
    "        self.norm2 = nn.LayerNorm(embedding_dim).to('cuda:0')\n",
    "        self.drop = nn.Dropout(residual_dropout).to('cuda:0')\n",
    "\n",
    "        self.attention = nn.MultiheadAttention(embedding_dim, num_heads, attention_dropout, batch_first=True).to('cuda:0')\n",
    "        self.mlp = nn.Sequential(\n",
    "            nn.Linear(embedding_dim, 4 * embedding_dim).to('cuda:0'),\n",
    "            nn.GELU(),\n",
    "            nn.Linear(4 * embedding_dim, embedding_dim).to('cuda:0'),\n",
    "            nn.Dropout(residual_dropout).to('cuda:0'),\n",
    "        )\n",
    "        # True value indicates that the corresponding position is not allowed to attend\n",
    "        self.register_buffer(\"attn_mask\", ~torch.tril(torch.ones(seq_len, seq_len, device='cuda:0')).to(bool))\n",
    "        # mask out previous value estimates (as they have information about future)\n",
    "        self.attn_mask[:, transition_dim - 1::transition_dim] = True\n",
    "\n",
    "    def forward(self, x, state=None, attn_pad_mask=None):\n",
    "        # state is a previous input to this layer\n",
    "        \n",
    "        x_norm = self.norm1(x)\n",
    "        #print(x.shape)\n",
    "\n",
    "        if state is None:\n",
    "            # if context_len < seq_len\n",
    "            \n",
    "            attn_mask = self.attn_mask[:x.shape[1], :x.shape[1]]\n",
    "            q, k, v = x_norm, x_norm, x_norm\n",
    "        else:\n",
    "            state = state.to('cuda:0')\n",
    "            assert x.size(1) == 1, f'when using memory input should be 1-time-step tensor, got {x.size(1)} timesteps.'\n",
    "            assert state.shape[1] + 1 <= self.seq_len, f\"{state.shape[1] + 1}\"\n",
    "\n",
    "            attn_mask = None\n",
    "            q, k, v = x_norm, torch.cat([state, x_norm], dim=1), torch.cat([state, x_norm], dim=1)\n",
    "\n",
    "        new_state = k\n",
    "        x = x + self.drop(self.attention(q, k, v, attn_mask=attn_mask, key_padding_mask=attn_pad_mask, need_weights=False)[0])\n",
    "        x = x + self.mlp(self.norm2(x))\n",
    "\n",
    "        return x, new_state\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "fe0e16e8-ed7b-4de8-a917-8a33ad36aa99",
   "metadata": {},
   "outputs": [],
   "source": [
    "attn_mask = ~torch.tril(torch.ones(509, 509)).to(bool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "2fa4b1b4-fc0c-48b4-a7ed-5bc19e26bcc5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[False,  True,  True,  ...,  True,  True,  True],\n",
       "        [False, False,  True,  ...,  True,  True,  True],\n",
       "        [False, False, False,  ...,  True,  True,  True],\n",
       "        ...,\n",
       "        [False, False, False,  ..., False,  True,  True],\n",
       "        [False, False, False,  ..., False, False,  True],\n",
       "        [False, False, False,  ..., False, False, False]])"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attn_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "9476b209-96da-4008-8138-5bff0157ac75",
   "metadata": {},
   "outputs": [],
   "source": [
    "block = TransformerBlock(51,509,128,1,0.1,0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "f48be07b-c7ff-49ab-8af4-b4d5b1c9689e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here\n"
     ]
    }
   ],
   "source": [
    "after_block = block(token_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "33b7875a-ea2c-42ef-b2a5-a30673b31991",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 509, 128])"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "after_block[0].size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d7bfbd7-52cb-4af1-a129-73d54ca1f2a4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
